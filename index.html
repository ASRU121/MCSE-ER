<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>Audio-visual End-to-end Multi-channel Speech Separation, Dereverberation and Recognition</title>
<style type="text/css">
<!--  body {-->
<!--  margin: 0  auto；-->
<!--  padding:10px 30px;-->
<!--  background: #fff;-->
<!--  color: #111;-->
<!--  font-size: 15px;-->
<!--  font-family: "Times New Roman", serif;-->
<!--  font-weight: 400;-->
<!--  line-height: 1.8;-->
<!--  -webkit-font-smoothing: antialiased;-->
<!--  }-->
  audio {  
  width: 75%;
  height:30px;
  }
  img {
  width:100%;
  }
  video {
  width:75%;
  }
  html{
  height:100%;
  }
  body{
  margin: 0  auto；
  padding:10px 30px;
  background: #fff;
  color: #111;
  height:100%;
  font-size: 17px;
  font-family: "Times New Roman", serif;
  font-weight: 400;
  line-height: 1.8;
  overflow-x: hidden;
  -webkit-font-smoothing: antialiased;
  }
</style>
</head>
<div style="border: none; width:80%; margin: 0 auto;">
<body>
    <h2 align="center">Multi-Channel Speech Enhancement for Cocktail Party Speech Emotion Recognition</h2>
    <p style="line-height:100%" align="justify"> <b>Abstract: </b>This paper highlights the critical importance of multi-channel speech enhancement (MCSE) for speech emotion recognition (ER) in cocktail party scenarios. A multi-channel speech dereverberation and separation front-end integrating DNN-WPE and mask-based MVDR is used to extract the target speaker's speech from the mixture, before being fed into the downstream ER back-end using HuBERT- and ViT-based speech and visual features. Experiments on mixture speech constructed using the IEMOCAP dataset suggest the MCSE output consistently outperforms domain fine-tuned single-channel speech representations produced by: a) Conformer-based metric GANs; and b) WavLM SSL features with optional further SE-ER dual task fine-tuning. Statistically significant increase of weighted, unweighted accuracy and F1 measures by up to 9.5%, 8.5% and 9.1% absolute (17.1%, 14.7% and 16.0% relative) are obtained over the above single-channel baselines. Consistent speech enhancement improvements were also obtained on PESQ, STOI and SRMR scores.</p>
    <a href="#sectionI">I. Multi-channel Speech Enhancement Front-end Architectures</a><br>
    <a href="#sectionII">II. Three pipelined Mulit-channel Speech Enhancement and Emotion Recognition Systems</a><br>
    <a href="#sectionIII">III. Experimental Setup and Results</a><br>
    <a href="#sectionIV">IV. Reference</a>
    <h3> <a name="sectionI"> I. Multi-channel Speech Enhancement Front-end Architectures </a> </h3>
    <div style="border: none; width:60%; margin: 0 auto;">
    <img border="0" src="frontend.png" alt="architectures of speech enhancement front-end" height="10%">
    </div>
    <ul>
        <li> In the pipelined integrated MCSE front-end, DNN-WPE based speech dereverberation is followed by mask-based MVDR speech separation, which can produce the best overall speech enhancement and recognition performance [1].</li>
    </ul>
    <ul>
        <li> The internal structural details of the TCN block and Visual Conv1DBlock are shown as following: </li>
    </ul>
    <div style="border: none; width:60%; margin: 0 auto;">
    <img border="0" src="tcn.png" alt="TCN block and Visual Conv1DBlock" height="5%">
    </div>
    <h3> <a name="sectionII">II. Three pipelined Emotion Recognition Systems </a> </h3>
    <div style="border: none; width:70%; margin: 0 auto;">
    <img border="0" src="arch.png" alt="architectures of emotion recognition systems" height="20%">
    </div>
    <p style="line-height:100%" align="justify"> <b> Three fine-tuning methods are investigated When training the systems:</b> </p>
    <ul>
        <li> Only fine-tuning the back-end ASR component using the enhanced speech outputs while the front-end remains unchanged. </li>
        <li> End-to-end jointly fine-tuning the entire system including the speech enhancement front-end and the recognition back-end components using the ASR cost function. </li>
        <li> End-to-end jointly fine-tuning the entire system using a multi-task criterion interpolation between the speech enhancement and recognition cost functions. </li>
    </ul>
    <h3> <a name="sectionIII">III. Experimental Setup and Results</a></h3>
    <div style="border: none; width:100%; margin: 0 auto;">
    <h4> A. Experimental setup </h4>
        <ul>
            <li> A 15-channel symmetric linear array with non-even inter-channel spacing is leveraged to simulate the multi-channel overlapped-reverberant-noisy mixture speech using the Oxford LRS2 dataset [3] with 96997, 4272 and 4972 utterances respectively for training (91.37 hours), validation (2.59 hours) and test (2.32 hours). </li>
            <li> 1200 (0.5 hours) utterances are recorded by replaying two loudspeakers simultaneously to generate a 15-channel overlapped-reverberant-noisy mixture speech in a meeting room [1], based on the Oxford LRS2 test set. The geometric specification of the microphone array used during recording is the same as that used in the simulation. </li>
            <li> Espnet style Conformer AED ASR model [4] contains 12 encoder and 6 decoder layers is used in the submitted paper. </li>
        </ul>
    <h4> B. Experimental results of speech enhancement front-end outputs and emotion recognition results on the simulated IEMOCAP mixture speech </h4>
    <table border="1">
    	<tr>
        	<th rowspan="2" colspan="2"></th>
        	<th colspan="4"> Four examples on the mixture speech with different emotion labels </th>
        </tr>
        <tr>
            <th>Sad</th>
            <th>Happy</th>
            <th>Neutral</th>
            <th>Angry</th>
        </tr>
          <tr>
            <th colspan="2"> Target speaker video</th>
            <td style="text-align:center">
                <video src="sad.mp4" controls="controls">
                    your browser does not support the video tag
                </video>
            </td>
            <td style="text-align:center">
                <video src="happy.mp4" controls="controls">
                    your browser does not support the video tag
                </video>
            </td>
            <td style="text-align:center">
                <video src=neutral.mp4 controls="controls">
                    your browser does not support the video tag
                </video>
            </td>
            <td style="text-align:center">
                <video src=angry.mp4 controls="controls">
                    your browser does not support the video tag
                </video>
            </td>
        </tr>
        <tr>
            <th colspan="2"> Target speech emotion label </th>
            <th>Sad</th>
            <th>Happy</th>
            <th>Neutral</th>
            <th>Angry</th>
        </tr>
        <tr>
            <th colspan="2"> Interfering speech emotion label </th>
            <th>Angry</th>
            <th>Angry</th>
            <th>Sad</th>
            <th>Happy</th>
        </tr>
        <tr>
            <th colspan="2"> Target clean speech</th>
             <td style="text-align:center">
                <img src="sad_clean.png" alt>
                <audio src="sad_clean.wav" controls="controls">
                    Your browser does not support the audio element.
                </audio>
            </td>
              <td style="text-align:center">
                <img src="happy_clean.png" alt>
                <audio src="happy_clean.wav" controls="controls">
                    Your browser does not support the audio element.
                </audio>
            </td>
            <td style="text-align:center">
                <img src="neutral_clean.png" alt>
                <audio src="neutral_clean.wav" controls="controls">
                    Your browser does not support the audio element.
                </audio>
            </td>
            <td style="text-align:center">
                <img src="angry_clean.png" alt>
                <audio src="angry_clean.wav" controls="controls">
                    Your browser does not support the audio element.
                </audio>
            </td>
        </tr>
        <tr>
            <th colspan="2">Mixture <br> (overlapped-reverberant-noisy) </th>
            <td style="text-align:center">
                <img src="sad_mixture.png" alt>
                <audio src="sad_mixture.wav" controls="controls">
                    Your browser does not support the audio element.
                </audio>
            </td>
            <td style="text-align:center">
                <img src="happy_mixture.png" alt>
                <audio src="happy_mixture.wav" controls="controls">
                    Your browser does not support the audio element.
                </audio>
            </td>
            <td style="text-align:center">
                <img src="neutral_mixture.png" alt>
                <audio src="neutral_mixture.wav" controls="controls">
                    Your browser does not support the audio element.
                </audio>
            </td>
            <td style="text-align:center">
                <img src="angry_mixture.png" alt>
                <audio src="angry_mixture.wav" controls="controls">
                    Your browser does not support the audio element.
                </audio>
            </td>
        </tr>
        <tr>
            <th colspan="2">Enhanced by speech dereverberation</th>
            <td style="text-align:center">
                <img src="sad_dervb.png" alt>
                <audio src="sad_dervb.wav" controls="controls">
                    Your browser does not support the audio element.
                </audio>
            </td>
              <td style="text-align:center">
                <img src="happy_dervb.png" alt>
                <audio src="happy_dervb.wav" controls="controls">
                    Your browser does not support the audio element.
                </audio>
            </td>
            <td style="text-align:center">
                <img src="neutral_dervb.png" alt>
                <audio src="neutral_dervb.wav" controls="controls">
                    Your browser does not support the audio element.
                </audio>
            </td>
            <td style="text-align:center">
                <img src="angry_dervb.png" alt>
                <audio src="angry_dervb.wav" controls="controls">
                    Your browser does not support the audio element.
                </audio>
            </td>
        </tr>
        <tr>
            <th colspan="2">Enhanced by speech separation</th>
            <td style="text-align:center">
                <img src="sad_mvdr.png" alt>
                <audio src="sad_mvdr.wav" controls="controls">
                    Your browser does not support the audio element.
                </audio>
            </td>
              <td style="text-align:center">
                <img src="happy_mvdr.png" alt>
                <audio src="happy_mvdr.wav" controls="controls">
                    Your browser does not support the audio element.
                </audio>
            </td>
            <td style="text-align:center">
                <img src="neutral_mvdr.png" alt>
                <audio src="neutral_mvdr.wav" controls="controls">
                    Your browser does not support the audio element.
                </audio>
            </td>
            <td style="text-align:center">
                <img src="angry_mvdr.png" alt>
                <audio src="angry_mvdr.wav" controls="controls">
                    Your browser does not support the audio element.
                </audio>
            </td>
        </tr>
        <tr>
            <th colspan="2">Enhanced by speech dereverberation and separation</th>
            <td style="text-align:center">
                <img src="sad_dervb_mvdr.png" alt>
                <audio src="sad_dervb_mvdr.wav" controls="controls">
                    Your browser does not support the audio element.
                </audio>
            </td>
              <td style="text-align:center">
                <img src="happy_dervb_mvdr.png" alt>
                <audio src="happy_dervb_mvdr.wav" controls="controls">
                    Your browser does not support the audio element.
                </audio>
            </td>
            <td style="text-align:center">
                <img src="neutral_dervb_mvdr.png" alt>
                <audio src="neutral_dervb_mvdr.wav" controls="controls">
                    Your browser does not support the audio element.
                </audio>
            </td>
            <td style="text-align:center">
                <img src="angry_dervb_mvdr.png" alt>
                <audio src="angry_dervb_mvdr.wav" controls="controls">
                    Your browser does not support the audio element.
                </audio>
            </td>
        </tr>
    </table>
    </div>
<h3><a name="sectionIV">IV. Reference</a></h3>
<p> [1] G. Li et al., “Audio-visual end-to-end multi-channel speech separation, dereverberation and recognition,” TASLP, vol. 31, pp. 2707–2723, 2023.</p>
<p> [1] J. Yu et al., “Audio-visual multi-channel recognition of overlapped speech,” in INTERSPEECH, 2020, pp. 3496–3500.</p>
<p> [2] G. Li et al., “Audio-visual multi-channel speech separation, dereverberation and recognition,” in ICASSP, 2022, pp. 6042–6046.</p>
<p> [3] J. Son Chung et al., “Lip reading sentences in the wild,” in IEEE Conf. Comput. Vis. Pattern Recognit., 2017, pp. 6447–6456. </p>
<p> [4] A. Gulati et al., “Conformer: Convolution-augmented transformer for speech recognition,” in INTERSPEECH, 2020, pp. 5036–5040</p>


</body>
</div>
</html>
